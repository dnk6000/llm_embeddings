Smart Query for Big Data

Реализован подход работы с нейросетями, позволяющий оптимизировать затраты на взаимодействие с LLM при работе с большими векторными базами данных. Векторная БД предварительно разбивается на фрагменты, которые преобразуются в эмбеддинги. Поступающий запрос пользователя также преобразуется в эмбеддинги. После этого происходит поиск наилучшего соответствия эмбеддингов базы знаний эмбеддингу запроса и только после этого выполняется обращение к LLM, с передачей не всей БД, а только необходимой для ответа на запрос. За счет этого происходит существенная экономия токенов. Для реализации использовалась библиотека langchain. В качестве базы данных использовалась выгрузка всей истории сообщений из telegram чата. 
Подход имеет большой потенциал развития - в плане предварительной обработки данных (многоступенчатость, предварительное использование более дешевых версий, использование локальных LLM, …) для нахождения оптимального соотношения цена/качество.
